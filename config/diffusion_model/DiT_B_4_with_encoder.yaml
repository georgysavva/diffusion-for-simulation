model:
  _target_: src.models.DiT_with_encoder.DiT
  num_actions: ${env.num_actions}
  num_conditioning_steps: 7
  input_size: 32
  in_channels: 4
  patch_size: 4
  hidden_size: 768
  depth: 12
  num_heads: 12
  mlp_ratio: 4.0
  time_frequency_embedding_size: 256
  learn_sigma: ${diffusion.learn_sigma}
  share_patch_embed: True


training:
  train_batch_size: 128
  eval_batch_size: 256
  lr_warmup_steps: 100

  optimizer:
    # base_lr: 3.90625e-7 # same scaling as dit
    base_lr: 7.8125e-7 # double scaling of dit
    scale_lr: True
  

